{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f514f06a",
   "metadata": {},
   "source": [
    "### Урок 1. Введение в задачу классификации. Постановка задачи и подготовка данных."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf85ea4a",
   "metadata": {},
   "source": [
    "**1. Приведите по 2 примера, когда лучше максимизировать Precision, а когда Recall.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960f7852",
   "metadata": {},
   "source": [
    "**I. Когда лучше максимизировать Precision:**\n",
    "1. В системе, распознающей (с дорожной камеры) номера автомашин нарушителей дорожного движения, и автоматически выписывающей им штрафы.\n",
    "2. В системе алгоритмической биржевой торговли, самостоятельно принимающей решения о покупке/продаже.\n",
    "\n",
    "**II. Когда лучше максимизировать Recall:**\n",
    "1. При анализе рентгеновских снимков на предмет наличия злокачественных новообразований.\n",
    "2. При анализе случаев мошенничества с кредитными картами."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5308cd7b",
   "metadata": {},
   "source": [
    "**2. Почему мы используем F-меру, почему, например, нельзя просто взять среднее от Precision и Recall?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15503bfc",
   "metadata": {},
   "source": [
    "F-score позволяет учитывать дисбаланс между Precision и Recall. Т.е. если, например, Precision стремится к 0, а Recall стремится к 1, то F-score будет ниже сред. арифметического Precision и Recall. Кроме того, F-score допускает тюнинг (в отличие от сред. арифметического), смещающий баланс в сторону Precision или Recall."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefd292f",
   "metadata": {},
   "source": [
    "**3. *Реализовать функции для подсчета Accuracy, Precision, Recall, F-score, которые на вход принимают y_true (истинные значения), y_pred (предсказанные значения), а на выход дается метрика.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22cd8086",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report,\\\n",
    "recall_score,f1_score, precision_score\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9307187f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perf_measure(y_true, y_pred):\n",
    "    '''\n",
    "    Вспомогательная функция для подсчета TN, FP, FN, TP\n",
    "    https://datascience.stackexchange.com/a/28500\n",
    "    '''\n",
    "    \n",
    "    TP, FP, TN, FN = 0, 0, 0, 0\n",
    "\n",
    "    for i in range(len(y_pred)): \n",
    "        if y_true[i]==y_pred[i]==1:\n",
    "           TP += 1\n",
    "        if y_pred[i]==1 and y_true[i]!=y_pred[i]:\n",
    "           FP += 1\n",
    "        if y_true[i]==y_pred[i]==0:\n",
    "           TN += 1\n",
    "        if y_pred[i]==0 and y_true[i]!=y_pred[i]:\n",
    "           FN += 1\n",
    "\n",
    "    return(TP, FP, TN, FN)\n",
    "\n",
    "\n",
    "def get_accuracy(y_true, y_pred):\n",
    "    TP, FP, TN, FN = perf_measure(y_true, y_pred)\n",
    "    \n",
    "    try: \n",
    "        result = (TP + TN)/(TP + FP + TN + FN)\n",
    "    \n",
    "    except ZeroDivisionError:\n",
    "        result = 0                    \n",
    "                           \n",
    "    return result\n",
    "\n",
    "\n",
    "def get_precision(y_true, y_pred):\n",
    "    TP, FP, _, _ = perf_measure(y_true, y_pred)\n",
    "    \n",
    "    try: \n",
    "        result = TP/(TP + FP)\n",
    "    \n",
    "    except ZeroDivisionError:\n",
    "        result = 0                    \n",
    "                           \n",
    "    return result\n",
    "\n",
    "\n",
    "def get_recall(y_true, y_pred):\n",
    "    TP, _, _, FN = perf_measure(y_true, y_pred)\n",
    "    \n",
    "    try: \n",
    "        result = TP/(TP + FN)\n",
    "    \n",
    "    except ZeroDivisionError:\n",
    "        result = 0                    \n",
    "                           \n",
    "    return result\n",
    "\n",
    "\n",
    "def get_f1_score(y_true, y_pred):\n",
    "    precision = get_precision(y_true, y_pred)\n",
    "    recall = get_recall(y_true, y_pred)\n",
    "    \n",
    "    try: \n",
    "        result = 2 * (precision * recall) / (precision + recall)\n",
    "    \n",
    "    except ZeroDivisionError:\n",
    "        result = 0                    \n",
    "                           \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb8fe159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred: [1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1]\n",
      "y_true: [1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1] \n",
      "\n",
      "Confusion matrix:\n",
      " [[ 8  5]\n",
      " [ 7 10]] \n",
      "\n",
      "Метрики sklearn: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.62      0.57        13\n",
      "           1       0.67      0.59      0.62        17\n",
      "\n",
      "    accuracy                           0.60        30\n",
      "   macro avg       0.60      0.60      0.60        30\n",
      "weighted avg       0.61      0.60      0.60        30\n",
      "\n",
      "Accuracy: 0.6\n",
      "Precision: 0.6666666666666666\n",
      "Recall: 0.5882352941176471\n",
      "F1-score: 0.625\n",
      "************************************************************ \n",
      "\n",
      "Свои метрики: \n",
      "\n",
      "Accuracy: 0.6\n",
      "Precision: 0.6666666666666666\n",
      "Recall: 0.5882352941176471\n",
      "F1-score: 0.625\n"
     ]
    }
   ],
   "source": [
    "y_true = [randint(0, 1) for i in range(30)]\n",
    "y_pred = [randint(0, 1) for i in range(30)]\n",
    "print(f'y_pred: {y_pred}')\n",
    "print(f'y_true: {y_true}', '\\n')\n",
    "print('Confusion matrix:\\n', confusion_matrix(y_true, y_pred),'\\n')\n",
    "print('Метрики sklearn:', '\\n')\n",
    "print(classification_report(y_true, y_pred))\n",
    "print(f'Accuracy: {accuracy_score(y_true, y_pred)}')\n",
    "print(f'Precision: {precision_score(y_true, y_pred)}')\n",
    "print(f'Recall: {recall_score(y_true, y_pred)}')\n",
    "print(f'F1-score: {f1_score(y_true, y_pred)}')\n",
    "print('*'*60, '\\n')\n",
    "print('Свои метрики: \\n')\n",
    "print(f'Accuracy: {get_accuracy(y_true, y_pred)}')\n",
    "print(f'Precision: {get_precision(y_true, y_pred)}')\n",
    "print(f'Recall: {get_recall(y_true, y_pred)}')\n",
    "print(f'F1-score: {get_f1_score(y_true, y_pred)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python385jvsc74a57bd08a49bb684e43ab00106799ded31d49934e1f306b7a86a273670123ff298874f2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
